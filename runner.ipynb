{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sentence transformer embeddings:\n",
    "Please create a new folder in the root (travel-vertical) called \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Qianfeng Wen\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|          | 0/794 [00:00<?, ?it/s]\n",
      "100%|██████████| 794/794 [00:00<00:00, 11889.13it/s]\n",
      "\n",
      "  0%|          | 0/794 [00:00<?, ?it/s]\n",
      "100%|██████████| 794/794 [00:00<00:00, 11439.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# create sentence transformer embeddings\n",
    "!python -m src.Embedder.embedderRunner -d data/clean_destination_air_canada_xml/ -o embeddings/ --emb_type st \n",
    "# create GPT embeddings\n",
    "!python -m src.Embedder.embedderRunner -d data/clean_destination_air_canada_xml/ -o embeddings/ --emb_type gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the query:\n",
    "1. The queries are stored in data/quries.txt\n",
    "2. Please choose your mode to process queries in MODE = {\"expand\", \"reformulate\", \"elaborate\"} or None (directly )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing queries:   0%|          | 0/5 [00:00<?, ?query/s]\n",
      "Processing queries:  20%|██        | 1/5 [00:05<00:23,  5.76s/query]\n",
      "Processing queries:  40%|████      | 2/5 [00:19<00:30, 10.21s/query]\n",
      "Processing queries:  60%|██████    | 3/5 [00:35<00:26, 13.22s/query]\n",
      "Processing queries:  80%|████████  | 4/5 [00:50<00:13, 13.79s/query]\n",
      "Processing queries: 100%|██████████| 5/5 [01:01<00:00, 12.86s/query]\n",
      "Processing queries: 100%|██████████| 5/5 [01:01<00:00, 12.35s/query]\n"
     ]
    }
   ],
   "source": [
    "!python -m src.QueryProcessor.queryProcessorRunner -i data/queries.txt -o output/ --mode elaborate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run dense retriever:\n",
    "1. query path is the proceesed queries' path from last stage.\n",
    "2. Please check if you are using the same embedding type with the first stage, i.e. GPT embedding can only process with GPT embedding, same as others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "\n",
      "Processing destinations: 0it [00:00, ?it/s]\n",
      "Processing destinations: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m src.Retriever.retrieverRunner -q output/processed_query_elaborate.pkl -e embeddings/text-embedding-3-small/ --emb_type gpt -o output/dense_results_gpt_elaborate.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview results of the first stage (Top 50 cities with their scores and top chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\EricWen\\Y3\\Summer\\travel-vertical\\src\\Retriever\\firstStageResultViewer.py\", line 3, in <module>\n",
      "    with open(\"output/dense_results_total_ela_top3_ST.json\", \"r\") as file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/dense_results_total_ela_top3_ST.json'\n"
     ]
    }
   ],
   "source": [
    "!python -m src.Retriever.firstStageResultViewer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
